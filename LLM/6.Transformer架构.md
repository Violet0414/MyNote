### Transformer的诞生

​		在Transformer诞生之前，序列建模（如机器翻译、文本生成）的主流是**循环神经网络（RNN）** 及其变体LSTM/GRU。RNN的核心问题是：

- **顺序处理**：必须逐个时间步处理序列，无法并行，计算效率低。
- **长程依赖问题**：尽管LSTM有所改善，但信息在长序列中传递时仍然会衰减或遗忘。

**卷积神经网络（CNN）** 可以被用于序列任务，它能够并行处理，但其**感受野有限**，需要堆叠很多层才能捕获长距离依赖。

**Transformer的诞生（2017，《Attention Is All You Need》）** 彻底改变了这一局面。它完全摒弃了循环和卷积结构，**仅依赖自注意力机制**，实现了：

1. **极高的并行能力**：整个序列同时被处理。
2. **强大的长程依赖建模**：任意两个位置元素的关联计算只需一步，无论距离多远。

---



### Transformer核心架构全景图

Transformer是一个**编码器-解码器** 架构。

#### 宏观工作流程（以机器翻译为例）：

1. **编码器**：读取源语言序列（如“I am a student”），将其转换为一个富含上下文信息的**中间表示**。
2. **解码器**：根据编码器的输出和**已生成的目标语言序列**（如“我 是”），自回归地（一个接一个）生成下一个词（如“一个”）。

---



### 核心组件深度解析

#### 自注意力机制 - 架构的灵魂

​		自注意力机制的目的是让序列中的**每个词**都能够与序列中的**所有其他词**进行交互，从而根据上下文来动态地计算该词的表示。

**核心思想**：对于序列中的每一个词，我们用它去“询问”序列中的所有词（包括自己），找到哪些词与它最相关，然后根据相关程度加权求和，来更新这个词的表示。

**计算过程（以矩阵形式理解）**：

1. **生成Q, K, V**：对于输入序列的每个词向量，我们通过三个不同的线性变换，生成三个新的向量：
   - **查询（Query）**：代表当前词在“寻找”什么。（比方说是水，这个水在哪里）
   - **键（Key）**：代表当前词可供“被匹配”的身份。（水附近是不是有一些相关的向量）
   - **值（Value）**：代表当前词实际的“信息内容”。）（这个水真正所含的值）
2. **计算注意力分数**：用每个词的Q去和所有词的K做点积，得到分数。分数越高，表示两个词越相关。
   - `分数 = Q · K^T`
3. **缩放与归一化**：将分数除以`√(d_k)`（Key向量的维度），以防止点积结果过大导致梯度消失。然后通过Softmax函数将分数转换为概率分布（权重和为1）。
   - `权重 = Softmax(分数 / √(d_k))`
4. **加权求和**：将上一步得到的权重，与所有词的V向量相乘并求和，得到当前词新的、经过上下文增强的表示。
   - `输出 = 权重 · V`

**为什么自注意力如此强大？**

- **全局视野**：一步计算即可捕获任意两个词之间的关系。
- **动态权重**：同一个词在不同的上下文中会获得不同的表示。例如，“苹果”在“吃苹果”和“苹果手机”中，其最终的表示向量是不同的，因为它关注的重点（“吃” vs “手机”）不同。

#### 多头注意力 - 增强表达能力

​		单一的自注意力机制可能只关注一种模式的依赖关系（例如语法结构）。多头注意力通过并行地进行多次自注意力计算（每个头有不同的Q、K、V投影矩阵），让模型能够**同时关注来自不同位置、不同子空间的信息**。

- **比喻**：就像我们用不同的视角阅读一篇文章——一个头关注主谓宾结构，一个头关注情感色彩，一个头关注指代关系。
- **操作**：将多个注意力头的输出拼接起来，再通过一个线性层融合，得到最终输出。

#### 位置编码 - 注入序列顺序信息

​		自注意力机制本身是**置换不变**的，即打乱输入序列的顺序，输出序列的集合不变（只是顺序也打乱）。这显然不符合语言等有序序列的需求。

​		**解决方案**：在输入词嵌入向量上，叠加一个**位置编码**，告诉模型每个词的位置信息。

- **正弦余弦编码**：原始论文使用了一组固定公式（不同频率的正弦和余弦函数）来生成位置编码。其优点是模型可以外推到比训练时更长的序列。
- **可学习的位置编码**：也可以将其视为模型参数进行学习。这在BERT等模型中常见。

#### 前馈神经网络 - 非线性变换与特征空间变换

​		每个注意力层后面都跟着一个**前馈神经网络**。它是一个简单的两层全连接网络，中间有一个ReLU激活函数。

- **作用**：对自注意力输出的表示进行非线性变换和空间映射，增强模型的表达能力。
- **特点**：它对序列中的**每个位置独立、相同地**进行计算，因此也可以并行。

#### 残差连接与层归一化 - 训练深度网络的利器

​		每个子层（自注意力层、前馈层）都包裹着：

- **残差连接**：将子层的输入和输出相加 `Output = Layer(X) + X`。这可以有效缓解深度网络中的梯度消失问题，使模型能够训练得更深。
- **层归一化**：对相加后的结果进行归一化，稳定训练过程，加速收敛。

---



### 编码器与解码器的差异

| 特性                      | **编码器**                                                   | **解码器**                                                   |
| :------------------------ | :----------------------------------------------------------- | :----------------------------------------------------------- |
| **自注意力层**            | **双向自注意力**：每个词可以关注输入序列中的所有词（包括前后的词）。 | **掩码自注意力**：每个词只能关注它**之前**的词（和它自己）。这是为了在训练和推理时保持**自回归**特性，防止“偷看”未来信息。 |
| **编码器-解码器注意力层** | 无                                                           | **有**。它的**Q**来自解码器上一层的输出，而**K和V**来自**编码器的最终输出**。这允许解码器在生成每个词时，有选择地聚焦于输入序列的不同部分。 |
| **输出**                  | 一组上下文向量，代表整个输入序列的语义。                     | 一个概率分布，表示下一个可能输出的词。                       |

---



### Transformer的深远影响与变体

Transformer不仅是自然语言处理的基石，其思想也正在向计算机视觉、音频处理等领域渗透。

1. **仅编码器模型**：
   - **代表**：BERT, RoBERTa
   - **特点**：使用双向上下文，非常适合**理解类任务**，如文本分类、命名实体识别、情感分析。它们通常通过预训练（如掩码语言模型）来学习强大的语言表示。
2. **仅解码器模型**：
   - **代表**：GPT系列（GPT-1/2/3/4）
   - **特点**：使用单向（从左到右）上下文，是纯粹的**生成模型**。通过预训练（预测下一个词）学习语言规律，然后在特定任务上通过提示（Prompt）或微调来使用。
3. **编码器-解码器模型**：
   - **代表**：原始Transformer, T5, BART
   - **特点**：适用于**序列到序列**的任务，如机器翻译、文本摘要、问答。
4. **视觉Transformer（ViT）**：
   - 将图像切割成一个个图像块（Patch），将这些块视为一个序列，然后直接输入到Transformer编码器中。它证明了纯Transformer架构在计算机视觉任务上也能达到甚至超过CNN的性能。

---



### Transformer的精髓

- **核心驱动力**：**自注意力机制**，实现了全局依赖和高效并行。
- **成功基石**：**多头注意力**、**位置编码**、**残差连接**与**层归一化**的巧妙结合，使得训练极深的网络成为可能。
- **架构哲学**：模块化、可扩展。编码器、解码器或其组合可以灵活地应用于不同场景。
- **范式影响**：它确立了“预训练 + 微调”的NLP新范式，并催生了**大语言模型（LLM）** 时代。

理解Transformer，不仅仅是理解其数学公式和模块组成，更是理解它如何通过一种简洁统一的机制，解决了序列建模的根本问题，并为通用人工智能（AGI）的探索开辟了全新的道路。

---



### 最终总结

|              | **CNN**              | **RNN**                     | **Transformer（作为参考）** |
| :----------- | :------------------- | :-------------------------- | :-------------------------- |
| **核心能力** | 提取**空间局部特征** | 建模**序列时序依赖**        | 计算**全局上下文依赖**      |
| **并行性**   | 高                   | 低                          | **极高**                    |
| **长程依赖** | 中等（通过深度）     | 差（基础RNN），中等（LSTM） | **极好**                    |
| **数据领域** | 图像、网格数据       | 文本、时间序列、语音        | 文本、图像、语音等          |
| **当前地位** | 计算机视觉的基石     | 被Transformer大量取代       | 自然语言处理的新霸主        |



​		妈的，看了B站上人话版的Transformer架构，已经有点怀疑自己是不是能听懂人话了

​		看下来大概了解了CNN/RNN和Transformer之间的区别，总的来说，**Transformer通过自注意力机制解决了原本串行计算下一步的输入需要完全依赖上一步输出的问题，实现了良好的并行性，这对于当下的模型训练提供了一个爆炸性突破的基础和前提。**









![](F:\MyNote\笔记图片\注意力机制.png)



![](F:\MyNote\笔记图片\Transformer核心流程.png)





![](F:\MyNote\笔记图片\Transformer与其他的对比.png)





















