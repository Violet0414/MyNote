### Loading文档加载组件

​	LlamaIndex 提供了丰富的文档加载器（`Document Loaders`），用于从各种数据源加载数据并转换为 `Document` 对象，为后续的索引和查询做准备。

#### 主要加载器类型

1. **文件加载器**

```python
from llama_index.core import SimpleDirectoryReader

# 加载目录中的所有文件
documents = SimpleDirectoryReader("./data").load_data()

# 加载特定文件类型
documents = SimpleDirectoryReader(
    "./data", 
    required_exts=[".pdf", ".txt"]
).load_data()
```



2. **PDF 加载器**

```python
from llama_index.readers.file import PDFReader

loader = PDFReader()
documents = loader.load_data(file="./document.pdf")

# 使用 PyPDF2
from llama_index.core import SimpleDirectoryReader

documents = SimpleDirectoryReader(
    "./data", 
    file_extractor={".pdf": PDFReader()}
).load_data()
```



3. **网页加载器**

```python
from llama_index.readers.web import SimpleWebPageReader

# 加载单个网页
documents = SimpleWebPageReader().load_data(urls=["https://example.com"])

# 加载多个网页
urls = ["https://site1.com", "https://site2.com"]
documents = SimpleWebPageReader().load_data(urls=urls)
```



4. **数据库加载器**

```python
from llama_index.readers.database import DatabaseReader

reader = DatabaseReader(
    scheme="postgresql",
    host="localhost",
    port="5432",
    user="user",
    password="password",
    dbname="database"
)

# 执行SQL查询加载数据
documents = reader.load_data(
    query="SELECT * FROM documents"
)
```



5. **Notion 加载器**

```python
from llama_index.readers.notion import NotionPageReader

integration_token = "your_integration_token"
page_ids = ["page_id_1", "page_id_2"]

documents = NotionPageReader(
    integration_token=integration_token
).load_data(page_ids=page_ids)
```



### 6. **API 加载器**

python

```python
from llama_index.readers.google import GoogleDocsReader
from google.oauth2.credentials import Credentials

# 加载 Google Docs
documents = GoogleDocsReader().load_data(
    document_ids=["doc_id_1", "doc_id_2"]
)
```



#### 高级配置

**自定义元数据**

```python
from llama_index.core import Document

# 创建带元数据的文档
document = Document(
    text="文档内容",
    metadata={
        "source": "my_file.pdf",
        "author": "John Doe",
        "date": "2024-01-01"
    }
)
```



**批量处理**

```python
from llama_index.core import SimpleDirectoryReader

# 批量加载并处理
reader = SimpleDirectoryReader(
    input_dir="./data",
    recursive=True,  # 递归读取子目录
    exclude_hidden=True,  # 排除隐藏文件
    filename_as_id=True  # 使用文件名作为ID
)

documents = reader.load_data()
```



**文件提取器配置**

```python
from llama_index.readers.file import PDFReader, DocxReader
from llama_index.core import SimpleDirectoryReader

# 为不同文件类型指定不同的加载器
file_extractor = {
    ".pdf": PDFReader(),
    ".docx": DocxReader(),
    ".txt": None  # 使用默认文本加载器
}

reader = SimpleDirectoryReader(
    "./data",
    file_extractor=file_extractor
)
```



#### 集成第三方加载器

**使用 LangChain 加载器**

```python
from llama_index.core import download_loader

# 下载并加载第三方加载器
WikipediaReader = download_loader("WikipediaReader")
loader = WikipediaReader()
documents = loader.load_data(pages=["Artificial Intelligence"])
```



**自定义加载器**

```python
from llama_index.core import BaseReader
from typing import List
from llama_index.core.schema import Document

class CustomReader(BaseReader):
    def load_data(self, file_path: str) -> List[Document]:
        # 实现自定义加载逻辑
        with open(file_path, 'r') as f:
            text = f.read()
        
        return [Document(
            text=text,
            metadata={"source": file_path}
        )]
```



#### 实际应用示例

**示例1：多源数据加载**

```python
from llama_index.core import SimpleDirectoryReader
from llama_index.readers.web import SimpleWebPageReader

# 加载本地文件
local_docs = SimpleDirectoryReader("./docs").load_data()

# 加载网页内容
web_docs = SimpleWebPageReader().load_data(
    urls=["https://docs.llamaindex.ai"]
)

# 合并文档
all_documents = local_docs + web_docs
```



**示例2：带预处理的数据加载**

```python
from llama_index.core import SimpleDirectoryReader
from llama_index.core.node_parser import SentenceSplitter

# 加载时进行文本分割
reader = SimpleDirectoryReader("./data")
documents = reader.load_data()

# 文本分割
splitter = SentenceSplitter(chunk_size=512)
nodes = splitter.get_nodes_from_documents(documents)
```



##### 示例3：增量加载

```python
from llama_index.core import SimpleDirectoryReader

# 只加载新文件或修改的文件
reader = SimpleDirectoryReader(
    "./data",
    recursive=True
)

# 获取文件信息
file_metadata = reader.get_file_metadata()

# 增量加载
new_documents = reader.load_data(
    exclude_files=[f["file_path"] for f in processed_files]
)
```



#### 最佳实践

1. **选择合适的加载器**：根据数据源类型选择专用加载器
2. **添加元数据**：为文档添加来源、时间戳等元数据
3. **预处理文本**：在加载时进行必要的文本清洗和标准化
4. **错误处理**：添加适当的异常处理
5. **批量处理**：对大文件进行分块处理，避免内存溢出

#### 注意事项

- 确保已安装必要的依赖：`pip install llama-index-readers-*`
- 处理特殊字符和编码问题
- 对于大文件，考虑使用流式加载
- 注意API调用频率限制（如网页加载器）

