### Querying查询引擎

​		**Querying 组件** 是检索增强生成（RAG）流程中的核心，负责根据查询从索引中检索相关信息，并生成最终答案。下面详细解析其主要组件和工作流程：

#### 一、核心组件

#### 1. **Retriever（检索器）**

负责从索引中获取相关上下文。

```python
from llama_index.core import VectorStoreIndex

# 创建检索器
retriever = index.as_retriever(
    similarity_top_k=3,  # 返回top-k相似节点
    vector_store_query_mode="default"  # 或 "sparse", "hybrid"
)

# 检索相关节点
nodes = retriever.retrieve("你的查询")
```



**常见检索器类型：**

- **VectorIndexRetriever**: 基于向量相似度
- **KeywordTableRetriever**: 基于关键词匹配
- **RouterRetriever**: 多路路由检索
- **AutoMergingRetriever**: 自动合并相关节点



#### 2. **Node Postprocessors（节点后处理器）**

对检索结果进行筛选和重排序。

```python
from llama_index.core.postprocessor import (
    SimilarityPostprocessor,
    KeywordNodePostprocessor,
    SentenceEmbeddingOptimizer
)

# 应用后处理器
retriever = index.as_retriever(
    node_postprocessors=[
        SimilarityPostprocessor(similarity_cutoff=0.7),  # 相似度阈值
        KeywordNodePostprocessor(required_keywords=["关键词"]),  # 必须包含关键词
        SentenceEmbeddingOptimizer(percentile_cutoff=0.5)  # 压缩文本
    ]
)
```



#### 3. **Response Synthesizer（响应合成器）**

将检索到的上下文合成为最终回答。

```python
from llama_index.core import get_response_synthesizer

response_synthesizer = get_response_synthesizer(
    response_mode="compact",  # 或 "refine", "tree_summarize", "simple_summarize"
    streaming=True  # 支持流式输出
)
```



#### 二、查询工作流程

#### 完整查询示例

```python
from llama_index.core import VectorStoreIndex, QueryBundle
from llama_index.core.retrievers import VectorIndexRetriever
from llama_index.core.postprocessor import SimilarityPostprocessor
from llama_index.core.response_synthesizers import get_response_synthesizer

# 1. 创建检索器
retriever = VectorIndexRetriever(
    index=index,
    similarity_top_k=5
)

# 2. 检索节点
query_bundle = QueryBundle(query_str="你的问题")
retrieved_nodes = retriever.retrieve(query_bundle)

# 3. 后处理
postprocessor = SimilarityPostprocessor(similarity_cutoff=0.75)
filtered_nodes = postprocessor.postprocess_nodes(
    retrieved_nodes, query_bundle
)

# 4. 合成响应
response_synthesizer = get_response_synthesizer(
    response_mode="refine",
    structured_answer_filtering=True
)

response = response_synthesizer.synthesize(
    query=query_bundle.query_str,
    nodes=filtered_nodes
)
```



#### 三、响应模式详解

#### 1. **compact（压缩模式）**

- 将相关上下文填充到提示中
- 单次LLM调用

```python
response_mode="compact"
```



#### 2. **refine（迭代精炼模式）**

- 多轮LLM调用逐步精炼答案
- 适合长文档

```python
response_mode="refine"
```



#### 3. **tree_summarize（树形总结模式）**

- 分层总结内容
- 适合极长文档

```python
response_mode="tree_summarize"
```



#### 4. **simple_summarize（简单总结模式）**

- 直接连接所有文本进行总结

```python
response_mode="simple_summarize"
```



#### 5. **accumulate（累积模式）**

- 为每个节点生成回答再合并

```python
response_mode="accumulate"
```



#### 6. **compact_accumulate（压缩累积模式）**

- 累积模式的压缩版本

```python
response_mode="compact_accumulate"
```



#### 四、高级查询特性

#### 1. **结构化输出**

```python
from llama_index.core import VectorStoreIndex
from pydantic import BaseModel

class Recipe(BaseModel):
    ingredients: list[str]
    steps: list[str]
    time: int

index = VectorStoreIndex.from_documents(documents)
query_engine = index.as_query_engine(
    output_cls=Recipe,  # 指定输出结构
    response_mode="compact"
)
```



#### 2. **多查询检索**

```python
from llama_index.core.retrievers import TransformRetriever
from llama_index.core.indices.query.query_transform import HyDEQueryTransform

# 使用HyDE生成假设文档
hyde = HyDEQueryTransform(include_original=True)
retriever = TransformRetriever(
    retriever, 
    query_transform=hyde
)
```



#### 3. **查询重写**

```python
from llama_index.core.indices.query.query_transform.base import (
    DecomposeQueryTransform
)

# 复杂查询分解
decompose_transform = DecomposeQueryTransform(
    llm, verbose=True
)
retriever = TransformRetriever(
    retriever,
    query_transform=decompose_transform
)
```



#### 五、查询引擎（QueryEngine）

#### 1. **标准查询引擎**

```python
query_engine = index.as_query_engine(
    similarity_top_k=3,
    response_mode="compact",
    streaming=True
)

# 查询
response = query_engine.query("你的问题")
print(response.response)  # 获取回答
for source_node in response.source_nodes:
    print(f"来源: {source_node.node.text[:100]}...")
```



#### 2. **子问题查询引擎**

```python
from llama_index.core.query_engine import SubQuestionQueryEngine

query_engine = SubQuestionQueryEngine.from_defaults(
    query_engine_tools=tools,  # 多个查询引擎
    use_async=True
)
```



#### 3. **多步骤查询引擎**

```python
from llama_index.core.query_engine import MultiStepQueryEngine

query_engine = MultiStepQueryEngine.from_defaults(
    query_engine_tools=tools,
    response_synthesizer=response_synthesizer
)
```



#### 六、查询流水线定制

#### 自定义查询流水线

```python
from llama_index.core import QueryPipeline
from llama_index.core.query_pipeline import (
    QueryComponent,
    InputComponent,
    Link
)

# 创建组件
class CustomRetriever(QueryComponent):
    # 自定义检索逻辑
    pass

# 构建流水线
pipeline = QueryPipeline(
    modules={
        "input": InputComponent(),
        "retriever": CustomRetriever(),
        "postprocessor": SimilarityPostprocessor(),
        "synthesizer": get_response_synthesizer()
    },
    links=[
        Link("input", "retriever"),
        Link("retriever", "postprocessor"),
        Link("postprocessor", "synthesizer")
    ]
)

# 执行查询
result = pipeline.run(query="你的问题")
```



#### 七、最佳实践建议

1. **检索优化**：
   - 根据数据特性选择合适的检索器
   - 使用混合检索提升召回率
   - 调整 `similarity_top_k` 平衡精度与召回
2. **后处理策略**：
   - 相似度过滤避免无关内容
   - 关键词过滤确保相关性
   - 去重避免重复信息
3. **响应合成**：
   - 短文档使用 `compact` 模式
   - 长文档使用 `refine` 或 `tree_summarize`
   - 需要结构输出时指定 Pydantic 模型
4. **性能调优**：
   - 使用异步查询提升并发性能
   - 缓存频繁查询结果
   - 批处理相似查询

#### 八、调试与监控

```python
# 启用调试日志
import logging
logging.basicConfig(level=logging.DEBUG)

# 获取中间结果
response = query_engine.query("问题")
print(response.metadata)  # 查看元数据
print(response.source_nodes)  # 查看来源

# 使用回调跟踪
from llama_index.core.callbacks import CallbackManager, LlamaDebugHandler

debug_handler = LlamaDebugHandler()
callback_manager = CallbackManager([debug_handler])
query_engine = index.as_query_engine(
    callback_manager=callback_manager
)
```