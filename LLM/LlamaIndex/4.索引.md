### **Indexing索引组件**

索引是将文档转换为可高效查询结构的过程。LlamaIndex提供了一系列灵活的索引类型，每种都针对不同的使用场景优化。

```python
from llama_index.core import VectorStoreIndex, Document

# 基础索引创建
documents = [Document(text="你的文档内容")]
index = VectorStoreIndex.from_documents(documents)
```



#### 二、核心索引类型详解

#### 1. **向量存储索引（VectorStoreIndex）**

**最常用的索引类型**，基于嵌入相似性进行检索。

```
from llama_index.core import VectorStoreIndex, Settings
from llama_index.embeddings.openai import OpenAIEmbedding

# 配置嵌入模型
Settings.embed_model = OpenAIEmbedding()

# 创建索引
index = VectorStoreIndex.from_documents(
    documents,
    show_progress=True  # 显示进度条
)

# 持久化存储
index.storage_context.persist(persist_dir="./storage")
```



#### 2. **摘要索引（SummaryIndex）**

提取文档摘要，适合需要整体理解的场景。

```python
from llama_index.core import SummaryIndex

index = SummaryIndex.from_documents(documents)

# 查询摘要
query_engine = index.as_query_engine(
    response_mode="tree_summarize"  # 树状总结模式
)
```



#### 3. **树状索引（TreeIndex）**

分层组织文档，支持从概括到详细的查询。

```python
from llama_index.core import TreeIndex

index = TreeIndex.from_documents(
    documents,
    num_children=2,  # 每个节点子节点数
    build_tree=True   # 构建树结构
)
```



#### 4. **关键词表索引（KeywordTableIndex）**

基于关键词匹配，不依赖嵌入模型。

```
from llama_index.core import KeywordTableIndex

index = KeywordTableIndex.from_documents(
    documents,
    max_keywords_per_chunk=10  # 每个块提取的关键词数
)
```



#### 5. **知识图谱索引（KnowledgeGraphIndex）**

提取实体和关系，适合复杂查询。

```
from llama_index.core import KnowledgeGraphIndex

index = KnowledgeGraphIndex.from_documents(
    documents,
    max_triplets_per_chunk=5,  # 每个块提取的三元组数
    include_embeddings=True    # 是否包含嵌入
)
```



#### 三、节点（Nodes）系统

节点是索引的基本构建块，LlamaIndex提供多种节点类型：

#### 文档分块策略

```python
from llama_index.core.node_parser import (
    SentenceSplitter,
    SemanticSplitterNodeParser,
    HierarchicalNodeParser
)

# 1. 句子分割器（默认）
splitter = SentenceSplitter(
    chunk_size=1024,
    chunk_overlap=200,
    separator="\n"
)

# 2. 语义分割器（基于嵌入相似性）
semantic_splitter = SemanticSplitterNodeParser(
    buffer_size=1,
    breakpoint_percentile_threshold=95
)

# 3. 分层解析器
hierarchical_splitter = HierarchicalNodeParser.from_defaults(
    chunk_sizes=[2048, 512, 128]  # 多层次分块
)
```



#### 节点元数据

```
from llama_index.core.schema import TextNode

node = TextNode(
    text="文本内容",
    metadata={
        "source": "document.pdf",
        "page": 5,
        "category": "technical"
    },
    excluded_embed_metadata_keys=["page"],  # 嵌入时排除的元数据
    excluded_llm_metadata_keys=["source"]   # LLM查询时排除的元数据
)
```



#### 四、存储上下文（StorageContext）

管理索引的持久化存储：

```python
from llama_index.core import StorageContext
from llama_index.vector_stores.chroma import ChromaVectorStore
import chromadb

# 配置向量存储
chroma_client = chromadb.PersistentClient(path="./chroma_db")
vector_store = ChromaVectorStore(chroma_collection=chroma_client.create_collection("docs"))

# 创建存储上下文
storage_context = StorageContext.from_defaults(
    vector_store=vector_store,
    docstore=SimpleDocumentStore(),      # 文档存储
    index_store=SimpleIndexStore(),      # 索引存储
    graph_store=SimpleGraphStore()       # 图存储（用于知识图谱）
)

# 使用存储上下文创建索引
index = VectorStoreIndex.from_documents(
    documents,
    storage_context=storage_context
)
```



#### 五、高级索引配置

#### 自定义检索器

```python
from llama_index.core.retrievers import VectorIndexRetriever

# 配置检索器
retriever = VectorIndexRetriever(
    index=index,
    similarity_top_k=5,           # 返回前5个相似结果
    vector_store_query_mode="default",
    alpha=0.5,                    # 混合检索权重（如使用MMR）
    filters=[MetadataFilter(key="category", value="technical")]
)

# 作为查询引擎使用
query_engine = RetrieverQueryEngine.from_args(retriever)
```



#### 多文档索引

```python
from llama_index.core import SimpleDirectoryReader
from llama_index.core.indices.composability import ComposableGraph

# 读取多个文档集
doc_set1 = SimpleDirectoryReader("docs1").load_data()
doc_set2 = SimpleDirectoryReader("docs2").load_data()

# 创建子索引
index1 = VectorStoreIndex.from_documents(doc_set1)
index2 = VectorStoreIndex.from_documents(doc_set2)

# 组合图索引
graph = ComposableGraph.from_indices(
    SummaryIndex,
    [index1, index2],
    index_summaries=["文档集1的摘要", "文档集2的摘要"]
)
```



#### 增量索引更新

```python
# 1. 加载已有索引
storage_context = StorageContext.from_defaults(persist_dir="./storage")
index = load_index_from_storage(storage_context)

# 2. 插入新文档
new_docs = [Document(text="新内容")]
index.insert(new_docs)

# 3. 更新特定文档
index.refresh_ref_docs([updated_document])

# 4. 删除文档
index.delete_ref_doc("doc_id")

# 5. 重新持久化
index.storage_context.persist()
```



#### 六、最佳实践建议

1. **索引选择策略**：

   - 简单QA：VectorStoreIndex
   - 文档总结：SummaryIndex
   - 复杂推理：KnowledgeGraphIndex + VectorStoreIndex组合
   - 关键词搜索：KeywordTableIndex

2. **分块优化**：

   ```python
   # 根据内容类型调整分块
   node_parser = SentenceSplitter(
       chunk_size=512 if technical else 1024,
       chunk_overlap=0.2,  # 20%重叠
       paragraph_separator="\n\n"
   )
   ```

   

3. **元数据增强**：

   ```python
   # 添加自定义元数据提取器
   from llama_index.core.extractors import (
       TitleExtractor,
       KeywordExtractor,
       SummaryExtractor
   )
   
   extractors = [
       TitleExtractor(nodes=5),
       KeywordExtractor(keywords=10),
       SummaryExtractor(summaries=["prev", "self"])
   ]
   ```

   

4. **性能监控**：

   ```
   # 启用回调追踪
   from llama_index.core.callbacks import CallbackManager
   
   callback_manager = CallbackManager([...])
   index = VectorStoreIndex.from_documents(
       documents,
       callback_manager=callback_manager
   )
   ```

   

#### 七、常见问题解决

1. **索引太大**：使用层次化索引或文档过滤
2. **检索不准**：调整分块策略和元数据过滤
3. **更新频繁**：实现增量更新策略
4. **多语言支持**：配置多语言嵌入模型

LlamaIndex的索引系统提供了强大的灵活性，可以根据具体需求组合不同的组件。建议从VectorStoreIndex开始，随着需求复杂化逐步引入更高级的索引类型和配置。