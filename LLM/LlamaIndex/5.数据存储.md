### Storing数据存储组件

LlamaIndex 提供了灵活的数据存储架构，支持将文档、索引、向量嵌入等持久化到不同存储后端。

#### 1. **向量存储 (Vector Stores)**

向量存储用于存储和管理文档的向量嵌入，支持快速相似性搜索。

**常用向量存储集成：**

- **Chroma**：轻量级，适合本地开发
- **Pinecone**：全托管的向量数据库
- **Weaviate**：开源向量数据库
- **Qdrant**：高性能向量搜索引擎
- **Milvus**：分布式向量数据库
- **FAISS**：Facebook 的向量相似性搜索库
- **PGVector**：PostgreSQL 的向量扩展

```python
# 使用 Chroma 向量存储示例
from llama_index.vector_stores.chroma import ChromaVectorStore
import chromadb

chroma_client = chromadb.PersistentClient(path="./chroma_db")
chroma_collection = chroma_client.get_or_create_collection("quickstart")
vector_store = ChromaVectorStore(chroma_collection=chroma_collection)
```



#### 2. **文档存储 (Document Stores)**

存储原始文档内容，通常与向量存储配合使用。

**类型：**

- **SimpleDocumentStore**：基于 JSON 的简单存储
- **MongoDocumentStore**：使用 MongoDB
- **FirestoreDocumentStore**：使用 Google Firestore

```python
from llama_index.core import StorageContext
from llama_index.core import VectorStoreIndex
from llama_index.vector_stores.chroma import ChromaVectorStore

# 创建存储上下文
storage_context = StorageContext.from_defaults(
    vector_store=vector_store,
    persist_dir="./storage"  # 持久化目录
)

# 构建索引并存储
index = VectorStoreIndex.from_documents(
    documents, 
    storage_context=storage_context
)

# 持久化到磁盘
index.storage_context.persist(persist_dir="./storage")
```



#### 3. **索引存储 (Index Stores)**

存储索引的元数据和结构信息。

```python
from llama_index.core import StorageContext
from llama_index.core import load_index_from_storage

# 保存索引
index.storage_context.persist(persist_dir="./storage")

# 加载索引
storage_context = StorageContext.from_defaults(persist_dir="./storage")
loaded_index = load_index_from_storage(storage_context)
```



#### 存储架构模式

#### 模式 1：单索引存储

```python
# 创建和存储单个索引
from llama_index.core import VectorStoreIndex, StorageContext
from llama_index.vector_stores.chroma import ChromaVectorStore

# 设置存储
vector_store = ChromaVectorStore.from_params(
    persist_directory="./chroma_db",
    collection_name="my_docs"
)

storage_context = StorageContext.from_defaults(
    vector_store=vector_store
)

# 创建索引
index = VectorStoreIndex.from_documents(
    documents, 
    storage_context=storage_context
)
```



#### 模式 2：多索引存储

```python
from llama_index.core import (
    VectorStoreIndex, 
    StorageContext,
    load_index_from_storage
)
from llama_index.core.indices.composability import ComposableGraph

# 创建多个索引
index1 = VectorStoreIndex.from_documents(docs1, storage_context=storage_context)
index2 = VectorStoreIndex.from_documents(docs2, storage_context=storage_context)

# 组合多个索引
graph = ComposableGraph.from_indices(
    [index1, index2],
    index_summaries=["Tech docs", "Business docs"]
)

# 保存组合图
graph.storage_context.persist(persist_dir="./multi_index_storage")
```



#### 持久化配置

#### 1. **本地文件存储**

```python
from llama_index.core import Settings
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.vector_stores.faiss import FaissVectorStore
import faiss

# 配置嵌入模型
Settings.embed_model = OpenAIEmbedding()

# 创建 FAISS 索引
d = 1536  # OpenAI 嵌入维度
faiss_index = faiss.IndexFlatL2(d)
vector_store = FaissVectorStore(faiss_index=faiss_index)

# 存储上下文
storage_context = StorageContext.from_defaults(
    vector_store=vector_store
)

# 持久化
storage_context.persist(persist_dir="./faiss_storage")
```



#### 2. **云存储集成**

```python
# Pinecone 示例
from llama_index.vector_stores.pinecone import PineconeVectorStore
import pinecone

pinecone.init(api_key="your-api-key", environment="us-west1-gcp")
pinecone_index = pinecone.Index("quickstart")
vector_store = PineconeVectorStore(pinecone_index=pinecone_index)

# Weaviate 示例
from llama_index.vector_stores.weaviate import WeaviateVectorStore
import weaviate

client = weaviate.Client("http://localhost:8080")
vector_store = WeaviateVectorStore(
    weaviate_client=client, 
    index_name="Document"
)
```



#### 数据管理操作

#### 1. **插入和更新文档**

```python
# 插入新文档
index.insert(document)

# 批量插入
index.insert_nodes(nodes)

# 刷新索引
index.refresh_ref_docs(documents)
```



#### 2. **删除文档**

```python
# 按 ID 删除
index.delete_ref_doc(ref_doc_id, delete_from_docstore=True)

# 批量删除
index.delete_ref_doc([id1, id2])
```



#### 3. **查询和检索**

```python
# 基础查询
query_engine = index.as_query_engine()
response = query_engine.query("查询内容")

# 带过滤的查询
from llama_index.vector_stores.types import MetadataFilter

filter = MetadataFilter(
    filters=[
        {"key": "category", "value": "technical", "operator": "=="}
    ]
)
query_engine = index.as_query_engine(
    vector_store_kwargs={"filter": filter}
)
```



#### 高级存储特性

#### 1. **混合存储策略**

```python
from llama_index.core import StorageContext
from llama_index.vector_stores.chroma import ChromaVectorStore
from llama_index.vector_stores.simple import SimpleVectorStore

# 使用多个向量存储
primary_store = ChromaVectorStore.from_params(...)
cache_store = SimpleVectorStore()

storage_context = StorageContext.from_defaults(
    vector_store=primary_store,
    vector_stores=[primary_store, cache_store]
)
```



#### 2. **存储观察器 (Hooks)**

```python
from llama_index.core.storage.docstore import BaseDocumentStore
from llama_index.core.schema import Document

class CustomDocumentStore(BaseDocumentStore):
    def add_documents(self, docs: List[Document], **kwargs):
        # 自定义逻辑
        super().add_documents(docs, **kwargs)
    
    def get_document(self, doc_id: str, **kwargs) -> Document:
        # 自定义获取逻辑
        return super().get_document(doc_id, **kwargs)
```



#### 最佳实践

1. **存储分离策略**：
   - 向量存储：处理相似性搜索
   - 文档存储：存储原始内容
   - 索引存储：管理索引结构
2. **备份和恢复**：

```python
# 定期备份
index.storage_context.persist(persist_dir=f"./backup_{timestamp}")

# 版本控制
import shutil
shutil.copytree("./storage", f"./versions/v{version_number}")
```



1. **性能优化**：
   - 批量插入文档
   - 使用向量存储的批处理 API
   - 定期清理旧数据
   - 使用索引缓存
2. **监控和维护**：

```python
# 检查存储状态
print(f"文档数量: {len(index.docstore.docs)}")
print(f"节点数量: {len(index.docstore.nodes)}")
print(f"索引大小: {index.index_struct}")
```



LlamaIndex 的存储系统设计灵活，可以根据应用需求选择合适的存储后端组合。生产环境建议使用专业的向量数据库（如 Pinecone、Weaviate）以获得更好的性能和可扩展性。