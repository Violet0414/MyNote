### LoRA和QLoRA

​		**LoRA(低秩适应)**，用于微调大模型时使用，其冻结了原有的大模型，通过训练外挂的适配器来微调模型，训练后对其进行叠加，保持主模型的权重不变。

​		**QLoRA(量化低秩适应)**，在外挂适配器之前，将大模型本体用高压缩比例压缩存储，在需要使用时临时还原，这样大大节省了GPU的存储空间。



### 详细对比

| 特性             | LoRA                                                         | QLoRA                                                        |
| :--------------- | :----------------------------------------------------------- | :----------------------------------------------------------- |
| **核心思想**     | **低秩适应**。冻结大模型，注入可训练的低秩分解矩阵。         | **量化 + 低秩适应**。先将基础模型量化为4-bit，再在其上应用LoRA。 |
| **模型权重状态** | **保持原精度**（通常是FP16/BF16）。权重被冻结，不更新。      | **被量化存储**（如NF4）。在训练时动态反量化为计算精度（BF16）用于前向和反向传播，但存储和梯度计算仍基于量化版本。 |
| **内存消耗**     | **较高**。需要加载完整的原精度模型参数。                     | **极低**。4-bit量化使模型加载的内存需求减少约4倍。这是其最大优势。 |
| **显存占用组成** | 模型参数（FP16） + 优化器状态（FP16） + 梯度 + LoRA参数 + 激活值。 | **模型参数（4-bit）** + 优化器状态（**仅针对LoRA参数，FP16**） + 梯度（**仅LoRA参数**） + 激活值。 |
| **可训练参数**   | 仅LoRA适配器（A和B矩阵）。                                   | 仅LoRA适配器（A和B矩阵）。                                   |
| **训练速度**     | 相对较快（因为模型是原精度计算）。                           | 稍慢一些，因为涉及动态反量化操作，带来了少量计算开销。       |
| **主要优势**     | 1. 大幅减少可训练参数量。 2. 多个任务适配器可轻松切换。 3. 无推理延迟（适配器可与原权重合并）。 | 1. **在同等硬件下能微调大得多的模型**（例如在24GB显存上微调65B模型）。 2. 继承了LoRA的所有优点。 3. **保证性能不降级**（与16位微调方法相当）。 |
| **关键技术点**   | 低秩分解、秩（r）的选择、适配器注入位置（通常为Q, K, V, O投影层）。 | **4-bit NormalFloat量化、双量化、分页优化器**。确保在极低精度下保持模型性能。 |
| **输出模型**     | 可以是： 1. 原模型 + 独立的`.safetensors`适配器文件。 2. 合并后的完整模型。 | 与LoRA相同。**关键**：最终可以生成一个**标准的、高精度的（如FP16）微调后模型**，与直接微调得到的结果无异。 |



​	**QLoRA不是LoRA的替代品，而是其为了极致内存优化而做的进化**。它通过创新的量化技术，将LoRA的“参数高效”优势推向了“内存高效”的极致， democratizing了大规模LLM的微调，让更多研究者和开发者能够参与到前沿模型的定制中。

目前，在资源受限的环境下，**QLoRA已成为微调LLM的事实标准方法**。

