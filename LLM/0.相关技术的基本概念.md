#### **什么是LLM**

​		**LLM(Large Language Model，大语言模型)**是一种基于深度学习的人工智能模型，通过海量文本数据的训练后，掌握了语言的统计规律和语义知识，从而能够用于理解、生成和处理自然语言。

--------------------------------



#### 什么是RAG

​		**RAG(检索增强生成)**是**LLM**的一种增强框架，通过结合外部知识库来**弥补纯LLM的局限性**，类似给LLM挂了个buff，获取知识的来源可以不局限原有的训练数据，**能够实时检索外部的知识和访问最新的信息从而提高最终回答的准确性**。简单来说，**RAG**给**LLM**提供了访问外部知识和增强答案准确性的功能。

**大致流程如下**

用户问题 → 检索器 → 相关文档 → LLM生成器 → 最终答案
    	 **↓**                		    							**↑**
 **外部知识库**             						   **增强提示**



**实际应用示例**

用户问题："我们公司最新的休假政策是什么?"

RAG工作流程：
1. 检索 → 从企业文档库中找到最新《员工手册》相关章节
2. 增强 → 将政策文档片段插入提示词
3. 生成 → LLM基于具体政策生成准确回答，并引用来源

----------------------------



#### 什么是嵌入

​	在LLM中，**嵌入(Embedding)**是一种将**离散的符号(如单词，句子)**转换为**连续的数值向量**的技术。简单来说，就是让计算机能够“理解”文本含义的数字表示。

##### 直观理解：从符号到向量

##### 传统方式 vs 嵌入方式

```python
# 传统One-hot编码（稀疏、无语义）
"猫" = [1, 0, 0, 0, 0, 0, ...]
"狗" = [0, 1, 0, 0, 0, 0, ...]
"老虎" = [0, 0, 1, 0, 0, 0, ...]

# 嵌入表示（密集、有语义）
"猫" = [0.2, 0.8, -0.3, 0.5, ...]    # 300维向量
"狗" = [0.3, 0.7, -0.2, 0.6, ...]    # 与"猫"相似
"数学" = [-0.8, 0.1, 0.9, -0.4, ...]  # 与"猫"差异大
```



#### 在LLM中的作用

1、**有助于LLM对于语义的理解**，将文字转换为具有语义的数值后，相似含义的词语在向量空间中的距离更近

2、可以进行**关系捕捉**

```python
# 经典的词向量关系示例
king - man + woman ≈ queen
巴黎 - 法国 + 德国 ≈ 柏林
```

3、**模型输入准备**，LLM无法直接处理文本，需转换为数值向量，嵌入层是LLM的第一层神经网络

------------------------------------------------

















