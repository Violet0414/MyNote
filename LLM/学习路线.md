## 📊 **学习路径全景图**

![LLM学习路线](F:\MyNote\笔记图片\LLM学习路线.png)



## 📚 **详细学习顺序与资源**

### **第一阶段：基础筑基（1-2个月）**

**目标：掌握大模型核心原理和向量化基础**

#### **第1-2周：Transformer深度理解**

1. **CS336课程系统学习**
   - 重点：注意力机制、位置编码、FFN层
   - 配套：[The Annotated Transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html)
2. **手写mini-GPT（必须！）**
   - Karpathy的[nanoGPT](https://github.com/karpathy/nanoGPT)
   - 简化版目标：
     - 实现GPT-2架构
     - 理解自回归生成
     - 掌握训练循环

#### **第3-4周：向量化技术核心**

1. **MTEB榜单研究**

   - 步骤：

     python

     复制下载

     ```
     # 1. 访问 https://huggingface.co/spaces/mteb/leaderboard
     # 2. 按任务筛选：Retrieval, Clustering, Classification
     # 3. 关注模型：BGE, E5, GTE
     ```

     

   - 实践：用sentence-transformers测试Top3模型

2. **向量索引算法**

   - HNSW原理（分层可导航小世界）
   - 对比学习：IVF, PQ, Flat索引
   - 实现：用faiss跑HNSW示例

#### **第5-6周：RAG框架入门**

1. **LlamaIndex深度使用**

   - 核心组件掌握：

     python

     复制下载

     ```
     # 必须理解的类
     from llama_index.core import (
         VectorStoreIndex,  # 向量索引
         SimpleDirectoryReader,  # 文档读取
         ServiceContext,  # 服务配置
         StorageContext  # 存储上下文
     )
     ```

     

   - 进阶：阅读`llama_index/core/indices/vector_store/`源码

   - 重点理解：查询引擎、检索器、响应合成器

### **第二阶段：进阶实战（2-3个月）**

**目标：构建完整的RAG系统并进行优化**

#### **第1个月：RAG优化全流程**

1. **文档切片策略实践**

   - 按场景选择策略：

     text

     复制下载

     ```
     📄 技术文档 → 按章节/函数切分
     📝 长篇文章 → 重叠滑动窗口
     🎥 会议记录 → 按发言人/话题切分
     ```

     

   - 工具：LlamaIndex的`NodeParser`系列

2. **向量数据库实战**

   - **Milvus** vs **Weaviate**选择建议：

     | 特性       | Milvus           | Weaviate     |
     | :--------- | :--------------- | :----------- |
     | 适用场景   | 超大规模向量检索 | 多模态+Graph |
     | 部署复杂度 | 较高             | 较低         |
     | 社区生态   | 中文友好         | 国际活跃     |

   - 建议：**先用Weaviate快速上手，再深入Milvus生产部署**

3. **效果评估体系建立**

   - 传统指标实现：

     python

     复制下载

     ```
     from rouge import Rouge
     from nltk.translate.bleu_score import sentence_bleu
     ```

     

   - LLM-as-Judge设计：

     python

     复制下载

     ```
     # 示例评估提示词
     judge_prompt = """
     请评估回答质量（1-10分）：
     问题：{query}
     参考答案：{reference}
     模型回答：{response}
     评分标准：准确性、完整性、流畅性
     """
     ```

     

#### **第2个月：模型微调技术**

1. **PEFT技术栈**

   - LoRA/QLoRA原理手绘图解
   - 实践：用PEFT库微调7B模型

2. **llamafactory一键微调**

   - 重点掌握：

     bash

     复制下载

     ```
     # 数据准备格式
     {
       "instruction": "...",
       "input": "...", 
       "output": "..."
     }
     
     # 启动训练
     llamafactory-cli train \
       --stage sft \
       --model_name_or_path Qwen/Qwen-7B \
       --dataset my_data
     ```

     

3. **训练方法对比**

   - SFT vs DPO vs GRPO
   - 损失函数和优势理解

#### **第3个月：模型部署与优化**

1. **vLLM深入使用**

   - 重点特性：

     - PagedAttention原理
     - 连续批处理
     - 量化支持

   - 部署实战：

     bash

     复制下载

     ```
     # 启动服务
     python -m vllm.entrypoints.openai.api_server \
       --model Qwen/Qwen-7B-Chat \
       --tensor-parallel-size 2
     ```

     

2. **量化技术实践**

   - 理解Trade-off：

     text

     复制下载

     ```
     🤖 精度：FP16 > GPTQ > AWQ > NF4
     ⚡ 速度：NF4 > AWQ > GPTQ > FP16  
     💾 显存：FP16 > GPTQ ≈ AWQ > NF4
     ```

     

   - 实践：用AutoGPTQ量化自己的模型

### **第三阶段：高级架构（1-2个月）**

**目标：构建复杂多Agent系统和工程化方案**

#### **第1个月：多Agent系统设计**

1. **LangGraph核心概念**

   - StateGraph设计模式
   - 节点与边的关系定义

2. **工作流设计实战**

   - 实现一个完整的客服Agent：

     python

     复制下载

     ```
     class CustomerServiceAgent:
         def __init__(self):
             self.graph = StateGraph(State)
             
             # 定义节点
             self.graph.add_node("classify", classify_intent)
             self.graph.add_node("retrieve", retrieve_knowledge)
             self.graph.add_node("generate", generate_response)
             
             # 定义边（工作流）
             self.graph.add_edge("classify", "retrieve")
             self.graph.add_edge("retrieve", "generate")
         ```
     ```

     

3. **SSE实时交互实现**

   - 前后端联调
   - 流式响应处理

#### **第2个月：LLMOps工程化**

1. **模型版本管理**
   - HuggingFace Hub实践
   - 自定义模型注册表
2. **A/B测试框架**
   - 设计分层实验
   - 效果指标监控
3. **全链路监控**
   - 关键指标：
     - 响应延迟（P95, P99）
     - Token消耗
     - 检索准确率
     - 用户满意度

## 🎯 **关键里程碑检查点**

| 时间点    | 需要完成的项目       | 验证标准                 |
| :-------- | :------------------- | :----------------------- |
| 第1个月末 | 手写mini-GPT运行成功 | 能生成连贯文本           |
| 第2个月末 | 完整RAG系统搭建      | MRR@10 > 0.7             |
| 第3个月末 | 微调并部署7B模型     | 在特定任务上超越基础模型 |
| 第4个月末 | 多Agent客服系统      | 支持5步以上对话          |
| 第5个月末 | 完整LLMOps流水线     | 支持自动化部署和监控     |